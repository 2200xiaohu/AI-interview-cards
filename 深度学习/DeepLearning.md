# Deep Learning Fundamental

# 初级

Q1：***深度学习和机器学习本质的区别在哪里？***

- 机器学习依赖于人类的因素更多，人需要手动选择更有效的特征并进行组合；深度学习使得大部分特征提取的步骤自动化，消除了人为干预的因素
- 机器学习对数据量的依赖程度低，**深度学习**需要大量数据才能提供更高精度

Q2：***深度学习的性能为什么会随着数据增多而提高？***

- 当输入学习算法的数据数量增加时，模型将考虑更多的边缘情况，因此算法将学习在这些边缘情况下做出正确的决策，提供更好的泛化性

Q3：***什么是ensemble learning，在深度学习中有何运用？***

- ensemble learning表示使用两个以上的模型学习，并使用某种规则将各个模型的学习结果整合，用于提高整体模型的*泛化*能力
- 深度学习中ensemble learning的运用有dropout、zoneout和drop-connect

Q4：**深度学习中，如何选择激活函数**？

- 如果要预测的输出是二元类的概率，那么可以使用Sigmoid 函数做网络输出层。
- 如果要预测的输出有两个类别，则可以使用Tanh 函数做网络输出层。
- 由于ReLU 函数计算简单，有利于抑制梯度消失情况，在网络中间层普遍使用

![Untitled](Deep%20Learning%20Fundamental%20f3253e927eb9461c9738fbc1e8ca2339/Untitled.png)

Q5：***相比机器学习，深度学习有什么优势？***

- 深度学习不需要设计模型的人对特征工程有很多理解，深度学习是端到端的，有利于快速上手
- 深度学习在数据集较大、建模问题较复杂的情况下，准确率更高

Q7：***如何判断深度学习模型中存在梯度消失问题？***

- 模型loss在训练阶段下降的非常缓慢
- 训练停止后（达到一定epoch），模型loss仍然很大
- 模型权重呈指数级缩小，训练模型阶段就变得非常小
- 训练阶段，模型权重变为零值

Q8：***如何判断深度学习模型是否存在梯度爆炸问题？怎么确定？***

- 以下现象表明你训练的模型可能存在梯度爆炸的问题，例如：模型无法很好地学习训练数据（模型损失一直很高）、模型训练不稳定（每一次更新，loss变化很大）、训练时loss变为NaN；
- 当发生以上现象时，可以深入挖掘模型看看是否有梯度爆炸的问题，以下现象可以确认发生梯度爆炸：训练阶段模型权重变为NaN；在训练期间，每个节点和层的误差梯度值始终高于`1.0`；

Q9：***Embedding Layer的作用是什么？***

- embedding层的目的是将模型的输入，one-hot向量（一种高维、稀疏的表示）映射到低维稠密的表示，节省模型的计算量

Q10：***什么是早停策略？***

- early-stopping：正则化的一种形式。NN使用梯度下降更新网络参数，但过了某个训练阶段，改进模型对训练数据的拟合会导致泛化误差增加。过了那个点，改进模型对训练数据的拟合会导致泛化误差增加。early-stopping规定了网络可以训练的迭代次数。

Q11：***什么是增量学习？***

- 增量学习是指算法从先前可用的数据集中生成分类器后，再从新数据中学习的能力
- 增量学习算法不断使用输入数据来扩展现有模型的知识，即使用动态的数据流，进一步训练模型；目的是让学习模型在不忘记其现有知识的情况下适应新数据

引用：[https://link.springer.com/](https://link.springer.com/)

Q12：***解释感知机的原理***

- 感知机是一种用于二元分类器监督学习的算法。其输入为实例的特征向量，输出为实例的类别，+1代表正类，-1代表负类。感知机属于判别模型，它的目标是要将输入实例通过分离超平面将正负二类分离。
- 感知机学习的目标就是求能将正负样本完全分开的分离超平面,即要寻找超平面参数w，b；感知机通过监督学习学习参数。

![Untitled](Deep%20Learning%20Fundamental%20f3253e927eb9461c9738fbc1e8ca2339/Untitled%201.png)

# 中级

Q13：***什么是计算图？哪些算法属于计算图模型？***

Q14：***线性激活函数和非线性激活函数之间有什么区别？***

Q15：***解释1*1卷积操作的意义？***

Q16：***在设计神经网络时，神经网络的广度和深度哪个更重要？***

Q17：***神经网络中的隐藏层计算的内容是什么？***

Q18：***神经网络中，可以将非线性激活函数替换为线性激活函数吗？为什么？***

Q19：***在深度学习模型中，如何选择损失函数？***

Q20：***介绍GAN的原理***

Q21：***什么是迁移学习？***

# 高级

Q22：***卷积层什么时候与全连接层等价？***

Q23：***GAN和自动编码器有什么区别和联系？***

Q24：***预训练对神经网络有什么好处？***

Q25：***在深度神经网络中使用Batch-Norm会有什么问题吗？***

Q26：***什么是multitask learning？什么时候使用它较为合适？***

Q27：***AE与VAE的区别是什么？***

Q28：***说一些你知道的CNN架构***

Q29：***什么是玻尔兹曼机？***

Q30：***你会选择那种神经网络完成视频分类任务？***

Q31：***dropout对神经网络训练有什么影响？***

Q32：***AE模型可以用于特征生成吗？如果可以，怎么做？***

Q33：***Batch Normalization、Instance Normalization、Layer Normalization、Group Normalization之间有什么区别？***

Q34：***同等参数量情况下，深层神经网络比浅层神经网络效果好的原理是什么？***

Q35：***比较svm和deep learning***

Q36：***Relu激活函数比sigmoid函数好的地方在哪里？***

Q37：***傅里叶变换在深度学习中有什么运用？***

Q38：***集成学习在深度学习中有什么运用？***

Q39：***深度学习怎么减轻/避免维度诅咒？***

Q40：***你了解多少种跳转链接（skip-connection）方法？***

Q41：什么是***Deep Recurrent Q-Network*?**

Q42：*****基于区域的目标检测神经网络*(R-CNN)、*Fast R-CNN*和*Faster R-CNN*之间有什么区别？**

Q43：***在处理序列问题上，比较HMM模型和RNN模型***

Q44：***知道哪些关于目标检测的网络结构？***

Q45：***GAN网络在训练时的难点是什么？***

Q46：***假设你想训练一个分类器，你有大量未标记的训练数据，但只有几千个标记实例。你将如何进行？***

Q47：***怎样使用遗传算法优化神经网络？***
